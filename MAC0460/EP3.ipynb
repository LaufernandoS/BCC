{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "yM8Skk6cEvcB",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "151a88f4e57da465816024ac50130028",
     "grade": false,
     "grade_id": "cell-fe17abb7219564fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# MAC0460 / MAC5832 (2025)\n",
    "<hr>\n",
    "\n",
    "# EP3: Logistic regression (binary classification)\n",
    "\n",
    "### Objectives:\n",
    "\n",
    "- to implement and test the logistic regression algorithm (binary classification with labels 0 and 1)\n",
    "\n",
    "### What to do: \n",
    "Some cells of this notebook must be filled. Cells to be filled are <mark>highlighted</mark> and places to be filled are indicated as:\n",
    "<code>\n",
    "    # YOUR CODE HERE:\n",
    "</code>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7a715c25940b79bd2b57a8457467169",
     "grade": false,
     "grade_id": "cell-403f8f75f7be44ad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## INSTRUCTIONS\n",
    "\n",
    "1. Fill in your identificatin information in the cell below, before submitting this notebook.\n",
    "2. Submit only this **notebook with all required cells filled and with the results of the execution** of all code cells\n",
    "3. Do not change function names and parameters\n",
    "4. Questions should be posted in the e-disciplinas discussion forum or sent to  mlimemonitoria@gmail.com\n",
    "5. By submitting this EP, you declare that the content being submitted is the result of your own work, and you did not resort to unethical means to do the EP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDENTIFICATION\n",
    "\n",
    "* Your name ==> _<mark>YOUR NAME HERE</mark>_\n",
    "* Pós, graduação, especial, ouvinte? ==> _<mark>YOUR CATEGORY HERE</mark>_\n",
    "* If you used some specific external source material or AI-based tools like ChatGPT or similar ones to do the EP, describe the sources you used and how they were used.<br>\n",
    "==> _<mark>Your answer here</mark>_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "oET7lkowAQkf",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "93dabd22bec2426f1596c1a54fed64ab",
     "grade": false,
     "grade_id": "cell-6833c0ba3623eb70",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### For this EP we will use automatic testing\n",
    "\n",
    "After every task, you will see a test cell to check your solution. We encourage you to experiment with these values to ensure your code is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c9be256791f1057c3b4af9cc2be56243",
     "grade": false,
     "grade_id": "cell-68569650e39ed38e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# All imports\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "34a65d7c292069ab51199d311d1e4401",
     "grade": false,
     "grade_id": "cell-b1d8e2547d1e1e74",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# <font style=\"background-color:#abebc6\">1. Training and prediction algorithms</font>\n",
    "\n",
    "We will use the formulation discussed in class: we use 1 for the positive class label and 0 for the negative class label. See Section 3.3.1 of \"Notas de aula\".\n",
    "\n",
    "In the next four code cells, write the code for the specified functions. These functions will be used afterwards for some training and prediction cases. Use vectorial computation with NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af2a35f5aa5de1e21f5075104e05b62f",
     "grade": false,
     "grade_id": "cell-759a79d788009b79",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this is the sigmoid function. Just use it\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "93b81928c0315bd3c30e7ddf32c6c712",
     "grade": false,
     "grade_id": "cell-75cd9d547a24d399",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## <font style=\"background-color: #f7dc6f\">1.1. Cross-entropy loss</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a37668adff2f497d3d0822d72fc3370",
     "grade": false,
     "grade_id": "cell-0f214ed1afa5d8ed",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cross_entropy_loss(w, X, y):\n",
    "    \"\"\"\n",
    "    Computes the cross-entropy loss \n",
    "    :param w: weight vector\n",
    "    :type: np.ndarray(shape=(1+d,1))\n",
    "    :param X: design matrix\n",
    "    :type X: np.ndarray(shape=(N,1+d))\n",
    "    :param y: class labels\n",
    "    :type y: np.ndarray(shape=(N,1))\n",
    "    :return loss: cross-entropy loss\n",
    "    :rtype: float\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c6658049a5d37bee69e8d3cde5e2d35",
     "grade": true,
     "grade_id": "cell-171f20cc4cc069fd",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CELL\n",
    "X_test = np.array([[1., 2.], [1., 3.], [1., 4.]])\n",
    "y_test = np.array([[0.], [1.], [1.]])\n",
    "w_test = np.array([[0.], [1.]])\n",
    "expected_cost = 0.731222\n",
    "assert np.isclose(cross_entropy_loss(w_test, X_test, y_test), expected_cost, atol=1e-1), \"Test for cross_entropy_loss failed\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32fd71c5b5bf7630811ea8197be2c093",
     "grade": false,
     "grade_id": "cell-5f3a98228ee41b1c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## <font style=\"background-color: #f7dc6f\">1.2. Gradient of the cross-entropy loss</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d94c5d6f944461642bc110b36598a692",
     "grade": false,
     "grade_id": "cell-498628d1a27734b5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cross_entropy_gradient(w, X, y):\n",
    "    \"\"\"\n",
    "    Computes the gradient of the loss function\n",
    "    :param w: weight vector\n",
    "    :type: np.ndarray(shape=(1+d,1))\n",
    "    :param X: design matrix\n",
    "    :type X: np.ndarray(shape=(N,1+d))\n",
    "    :param y: class labels\n",
    "    :type y: np.ndarray(shape=(N,1))\n",
    "    :return grad: gradient \n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17e72cf2322345b6ada16f43a01df371",
     "grade": true,
     "grade_id": "cell-3c087f124dde04ef",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CELL\n",
    "X_test = np.array([[5., 0.], [1., 6.], [9., 2.]])\n",
    "y_test = np.array([[0.], [1.], [0.]])\n",
    "w_test = np.array([[0.], [7.]])\n",
    "expected_grad = np.array([[3.83333084], [0.66666611]])\n",
    "assert np.allclose(cross_entropy_gradient(w_test, X_test, y_test), expected_grad, 1e-1), \"Test for cross_entropy_gradient failed\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d3e63668d4f27cee47f57af30331b89b",
     "grade": false,
     "grade_id": "cell-9bcd492bc18f03c6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## <font style=\"background-color: #f7dc6f\">1.3 Logistic regression training</font>\n",
    "\n",
    "The function below receives the extended data matrix <tt> X (shape = (N, d+1))</tt> and the ouput vector <tt>y (shape = (N,1))</tt>, and should return the final weight vector <tt>w (shape = (d+1,1))</tt> and a list of size <tt>num_iterations+1</tt> with the cross-entropy loss values at the beginning and after each of the iterations, when <tt>return_history</tt> is <tt>True</tt>, or a Null list otherwise.\n",
    "\n",
    "If <tt>w0==None</tt>, then it must be initialized  with <tt>w0 = np.random.normal(loc = 0, scale = 1, size = X.shape[1])</tt>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c80b114d34430f76fc993ea6672bc24e",
     "grade": false,
     "grade_id": "cell-0b0b00f0c27d5190",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_logistic(X, y, learning_rate = 1e-3, w0 = None,\\\n",
    "                        num_iterations = 300, return_history = False):\n",
    "    \"\"\"\n",
    "    Computes the weight vector applying the gradient descent technique\n",
    "    :param X: design matrix\n",
    "    :type X: np.ndarray(shape=(N,d+1))\n",
    "    :param y: class label\n",
    "    :type y: np.ndarray(shape=(N,1))\n",
    "    :return: weight vector\n",
    "    :rtype: np.ndarray(shape=(1+d,1))\n",
    "    :return: the history of loss values (optional)\n",
    "    :rtype: list of floats\n",
    "    \"\"\"    \n",
    "\n",
    "    # Initialize the weight vector with random values\n",
    "    # Here, drawn indenpendently from a normal unit distribution\n",
    "    if w0 is None:\n",
    "        w0 = np.random.normal(loc = 0, scale = 1, size = X.shape[1]).reshape(X.shape[1],1)\n",
    "    w = w0\n",
    "    # To store the cross entropy value at each iteration\n",
    "    history = []\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "59634dce1b7d01e357d083046a967131",
     "grade": true,
     "grade_id": "cell-e695ba125bb7b240",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CELL\n",
    "X_test = np.array([[1., 2.], [1., 3.], [1., 4.]])\n",
    "y_test = np.array([[0.], [1.], [1.]])\n",
    "w_test = np.array([[0.], [0.]])\n",
    "expected_w_final = np.array([[-3.19581162], [ 1.47454342]])\n",
    "learning_rate = 0.05\n",
    "num_iters = 1000\n",
    "expected_loss_history_length = num_iters + 1\n",
    "w_final, loss_history = train_logistic(X_test, y_test, learning_rate, w_test, num_iters, return_history=True)\n",
    "assert np.allclose(w_final, expected_w_final, atol=1e-1), \"Test failed for train_logistic: w_final incorrect\"\n",
    "assert len(loss_history) == expected_loss_history_length, \"Test failed for train_logistic: loss history length incorrect\"\n",
    "\n",
    "w_final, loss_history = train_logistic(X_test, y_test, learning_rate, w_test, num_iters, return_history=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a7e320faba65fc72bc60cfd77b920af9",
     "grade": false,
     "grade_id": "cell-5a63d0b1592ef55a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## <font style=\"background-color: #f7dc6f\">1.4. Logistic regression prediction</font>\n",
    "\n",
    "The function in the next cell will be used to do the prediction. Recall that the prediction is a score in $[0,1]$, given by the sigmoid value of the linear combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1dd4168becdd4fa49b1ac6f62ff4624",
     "grade": false,
     "grade_id": "cell-5ab00d83e8ded78c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def predict_logistic(X, w):\n",
    "    \"\"\"\n",
    "    Computes the logistic regression prediction\n",
    "    :param X: design matrix\n",
    "    :type X: np.ndarray(shape=(N,d+1))\n",
    "    :param w: weight vector\n",
    "    :rtype: np.ndarray(shape=(1+d,1))\n",
    "    :return: predicted classes \n",
    "    :rtype: np.ndarray(shape=(N,1))\n",
    "    \"\"\"\n",
    "\n",
    "    # Make sure the data matrix has a bias coordinate\n",
    "    #if X.shape[1] != w.shape[0]:\n",
    "        # Add a bias value 1 as the first coordinate of each vector\n",
    "        # X = np.concatenate([np.ones((len(X), 1)), X], axis = 1)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d8545d8373ac75320618eff21755433",
     "grade": true,
     "grade_id": "cell-0f34bf481567da72",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CELL\n",
    "X_test = np.array([[1., 2.], [1., 0.], [1., 4.]])\n",
    "w_test = np.array([[0.], [1.]])\n",
    "expected_predictions = np.array([[0.88079708], [0.5], [0.98201379]])\n",
    "predictions = predict_logistic(X_test, w_test)\n",
    "assert np.allclose(predictions, expected_predictions, atol=1e-1), \"Test failed for prediction_logistic\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f1b0cb18ffceb152a17581292ff2b34",
     "grade": false,
     "grade_id": "cell-228773a5d7a4e797",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# <font style=\"background-color:#abebc6\">2. Testing the training and prediction algorithms on toy datasets</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c48fa6681136879ba312d606c6f750be",
     "grade": false,
     "grade_id": "cell-aca7606162276a54",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.1. 2D data, separable case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1978d4399c290bff581a8885dd4455d1",
     "grade": false,
     "grade_id": "cell-2814a2f7b2c5b33d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.1.1. Generate two blobs of points\n",
    "\n",
    "---\n",
    "\n",
    "In this code cell, change the variable `data_type` to produce different types of observations.\n",
    "- \"regular\" corresponds to clean data with two distinct classes where a decision boundary can be drawn very easily.\n",
    "- \"unbalaced\" is a type of dataset where one class has way more observations than the other.\n",
    "- \"overlapping\" is a dataset where there is not a clearly distinct decision boundary to separate both classes (at least not in this dimension).\n",
    "\n",
    "---\n",
    "\n",
    "Play around with these dataset types and make observations.\n",
    "You can also change the variable `unbalance_mod` to change the inbalance level between the classes or `overlap_std` to change how much the two classes overlap. For example, if `unbalance_mod = 10` there will be 10 times more example in class 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9bacf60196819acf26a0435b2b2beff1",
     "grade": false,
     "grade_id": "cell-fe91020c199c1b16",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create two blobs\n",
    "N = 300\n",
    "# change this variable to test different types of data. Possible values: \"regular\", \"unbalanced\", \"overlapping\".\n",
    "dataset_type = \"unbalanced\"\n",
    "# change this variable to test different magnitudes of inbalance\n",
    "unbalance_mod = 5\n",
    "# change this variable to test different magnitudes of overlap between classes\n",
    "overlap_std = 0.5\n",
    "\n",
    "if dataset_type == \"regular\":\n",
    "  X, y = make_blobs(n_samples=N, centers=2, cluster_std=0.1, center_box=(-1.0, 1.0), n_features=2, random_state=2)\n",
    "\n",
    "elif dataset_type == \"unbalanced\":\n",
    "  X, y = make_blobs(n_samples=N, centers=2, cluster_std=0.2, center_box=(-1.0, 1.0), n_features=2, random_state=2, shuffle=False)\n",
    "  len_0 = (y==0).sum()\n",
    "  slice_idx = int(len_0/unbalance_mod)\n",
    "  X = X[len_0-slice_idx:]\n",
    "  y = y[len_0-slice_idx:]\n",
    "  p = np.random.permutation(len(X))\n",
    "  X = X[p]\n",
    "  y = y[p]\n",
    "\n",
    "elif dataset_type == \"overlapping\":\n",
    "  X, y = make_blobs(n_samples=N, centers=2, cluster_std=overlap_std, center_box=(-1.0, 1.0), n_features=2, random_state=2)\n",
    "\n",
    "else:\n",
    "  raise NotImplementedError(\"Please choose a valid dataset_type\")\n",
    "\n",
    "# Add a bias value 1 as the first coordinate of each example\n",
    "Xtilde = np.concatenate([np.ones((len(X), 1)), X], axis = 1)\n",
    "\n",
    "y = y.reshape(len(y),1)\n",
    "print(\"X\", X.shape)\n",
    "print(\"Xtilde\", Xtilde.shape)\n",
    "print(\"y.shape =\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d746b82a71073b6e4c26c2426c365f6",
     "grade": false,
     "grade_id": "cell-05cb4ca9c384cfda",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.1.2. Let's plot the blobs of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9dd703f21e4cd53486432008ea7b92fa",
     "grade": false,
     "grade_id": "cell-9dd4fe314b4f6f27",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "\n",
    "# plot negatives in red\n",
    "plt.scatter(X[y[:,0]==0,0], \\\n",
    "            X[y[:,0]==0,1], \\\n",
    "            alpha = 0.5,\\\n",
    "            c = 'red')\n",
    "\n",
    "# and positives in blue\n",
    "plt.scatter(x=X[y[:,0]==1,0], \\\n",
    "            y=X[y[:,0]==1,1], \\\n",
    "            alpha = 0.5, \\\n",
    "            c = 'blue')\n",
    "\n",
    "P=1\n",
    "N=0\n",
    "legend_elements = [ Line2D([0], [0], marker='o', color='r',\\\n",
    "                    label='Class %d'%N, markerfacecolor='r',\\\n",
    "                    markersize=10),\\\n",
    "                    Line2D([0], [0], marker='o', color='b',\\\n",
    "                    label='Class %d'%P, markerfacecolor='b',\\\n",
    "                    markersize=10) ]\n",
    "\n",
    "plt.legend(handles=legend_elements, loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d97db719083acf03311349e802cc42ec",
     "grade": false,
     "grade_id": "cell-b063792e3e432100",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <font style=\"background-color: #f7dc6f\">2.1.3. Let's train the logistic regressor and plot the loss curve</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fd2de83c8963c83da89909799eb84fd4",
     "grade": false,
     "grade_id": "cell-879275ed92eb84a4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_logistic_regression_result(Xtilde, y, learning_rate=0.5, num_iterations=1000, return_history=True):\n",
    "    \"\"\"\n",
    "    Trains a logistic regression model using gradient descent.\n",
    "\n",
    "    This auxiliary function wraps the call to `train_logistic()` and is \n",
    "    used to enable automatic testing of logistic regression training.\n",
    "\n",
    "    In submission\n",
    "    \n",
    "    :param Xtilde: design matrix with bias term included\n",
    "    :type Xtilde: np.ndarray of shape (N, d+1)\n",
    "    :param y: binary class labels\n",
    "    :type y: np.ndarray of shape (N, 1)\n",
    "    :param learning_rate: step size for gradient descent\n",
    "    :type learning_rate: float\n",
    "    :param num_iterations: number of gradient descent iterations\n",
    "    :type num_iterations: int\n",
    "    :param return_history: whether to return loss history\n",
    "    :type return_history: bool\n",
    "    :return: final weight vector and (optionally) loss history\n",
    "    :rtype: tuple (np.ndarray, list of float)\n",
    "    \"\"\"\n",
    "    np.random.seed(567) # Do not change this line!\n",
    "\n",
    "    # ==> Replace the right hand side below with a call to the\n",
    "    # train_logistic() function defined above. Use parameter return_history=True\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4855450b39320c2c6d3eee8baaa4009",
     "grade": true,
     "grade_id": "cell-c973936dbe1ae348",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CELL\n",
    "w_final, loss_hist = get_logistic_regression_result(Xtilde, y)\n",
    "\n",
    "assert loss_hist[-1] < loss_hist[0], \"Test for get_logistic_regression_result failed: Loss did not decrease\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c04e6bb625fc5b4e063952aeea74afc8",
     "grade": false,
     "grade_id": "cell-ad987d1895c48408",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "w_logistic, loss = get_logistic_regression_result(Xtilde, y)\n",
    "print()\n",
    "print(\"Final weight:\\n\", w_logistic)\n",
    "print()\n",
    "print(\"Final loss:\\n\", loss[-1])\n",
    "    \n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.plot(loss)\n",
    "plt.xlabel('Iteration #')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6c00f201ddd96e30329054839ee00c79",
     "grade": false,
     "grade_id": "cell-e504076b75655b87",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.1.4. Now, let's plot the decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f37f01530e898ff6ca574d00244371e0",
     "grade": false,
     "grade_id": "cell-9f914dc9a8ed47a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x1min = min(X[:,0])\n",
    "x1max = max(X[:,0])\n",
    "x2min = min(X[:,1])\n",
    "x2max = max(X[:,1])\n",
    "\n",
    "y_pred = predict_logistic(Xtilde, w_logistic)\n",
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.set_title(\"Ground-truth\")\n",
    "\n",
    "# plot negatives in red\n",
    "ax1.scatter(X[y[:,0]==0,0], \\\n",
    "            X[y[:,0]==0,1], \\\n",
    "            alpha = 0.5, \\\n",
    "            c = 'red')\n",
    "\n",
    "# and positives in blue\n",
    "ax1.scatter(x=X[y[:,0]==1,0], \\\n",
    "            y=X[y[:,0]==1,1], \\\n",
    "            alpha = 0.5, \\\n",
    "            c = 'blue')\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "ax2.set_title(\"Prediction\")\n",
    "ax2.scatter(x = X[:,0], y = X[:,1], c = -y_pred, cmap = 'coolwarm')\n",
    "ax2.legend(handles=legend_elements, loc='best')\n",
    "#ax2.set_xlim([x1min-1, x1max+1])\n",
    "#ax2.set_ylim([x2min-1, x2max+1])\n",
    "\n",
    "p1 = (x1min, -(w_logistic[0] + (x1min)*w_logistic[1])/w_logistic[2])\n",
    "p2 = (x1max, -(w_logistic[0] + (x1max)*w_logistic[1])/w_logistic[2])\n",
    "\n",
    "lines = ax2.plot([p1[0], p2[0]], [p1[1], p2[1]], '-')\n",
    "plt.setp(lines, color='g', linewidth=2.5)\n",
    "\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "16d19957fb68b9b9e27185a8ac979d35",
     "grade": false,
     "grade_id": "cell-88da679bf15ae874",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <font style=\"background-color: #f7dc6f\">2.1.5.  Counting errors</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dcd69f529558bea7710f0678557ed237",
     "grade": false,
     "grade_id": "cell-d689238c45d464fe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def count_errors(y, y_pred):\n",
    "    \"\"\"\n",
    "    Function to count the numbers of missclassifications\n",
    "    :param y: binary class labels\n",
    "    :type y: np.ndarray of shape (N, 1)\n",
    "    :param y_pred: binary class predicted labels\n",
    "    :type y_pred: np.ndarray of shape (N, 1)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9ea60872c7345d9004117bd479a5150",
     "grade": true,
     "grade_id": "cell-fc169ab8b4a1b6b3",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST CELL\n",
    "y_pred_test = np.array([[0.4], [0.7]])\n",
    "y_test = np.array([[1.], [1.]])\n",
    "expected_num_errors = 1\n",
    "assert expected_num_errors == count_errors(y_test, y_pred_test), \"Error for count_errors function. Wrong num of missclassfications.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a36e3a08660a57af2960f33f185c7f3",
     "grade": false,
     "grade_id": "cell-8ca1bf3f439a8734",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "y_pred = predict_logistic(Xtilde, w_logistic)\n",
    "errors = count_errors(y, y_pred)\n",
    "print(\"Number of misclassified examples: \", errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "049837e2e5251a9925ad4580f219084d",
     "grade": false,
     "grade_id": "cell-799f0769ca0d429a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.2.  2D data, overlapping or unbalanced blobs\n",
    "\n",
    "Feel free to experiment variations regarding total number of points, spread or number of points in each class, learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c6ddf449113b7e74d981f473b9895662",
     "grade": false,
     "grade_id": "cell-34df95d34aed8f9a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# <font style=\"background-color:#abebc6\">3. More than 2 input variables</font>\n",
    "\n",
    "To this end, we will play with the dataset we have collected. The file with the dataset is <tt>dataMAC0460_5832.csv</tt>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20ef8a1103596042b6583247b60b60f3",
     "grade": false,
     "grade_id": "cell-e985681dccf6e466",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv('dataMAC0460_5832.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dcc36d908c3077347c299d91071ee9b4",
     "grade": false,
     "grade_id": "cell-e75331e6ebf33e28",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df1 = df.replace('Female', 0)\n",
    "df = df1.replace('Male', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70aa4dd024ddc24dfd31d7011f35a12e",
     "grade": false,
     "grade_id": "cell-1f6bc9cd055012e9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11170f81d0cc35b6e7560ef5d01d376d",
     "grade": false,
     "grade_id": "cell-900891325536c04a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "y = df[['Sex']].to_numpy()\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "efe7ea8116324a53c82e2b1947e46526",
     "grade": false,
     "grade_id": "cell-3f8c2eb8c89de445",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Sex'])\n",
    "df =(df-df.mean())/df.std()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c3d6acd5cb570e1fd69e0158f16c832",
     "grade": false,
     "grade_id": "cell-15831ed59db33b7f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cac40bd09babcdfee6fa74743877a03c",
     "grade": false,
     "grade_id": "cell-02bdd51ab28ae384",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "\n",
    "  print(\"\\n\\nNumber of input variables = %d\\n\"%(i+1))\n",
    "    \n",
    "  Xtilde = np.concatenate([np.ones((len(X), 1)), X[:,0:i+1]], axis = 1)  # data matrix, with left column of ONEs\n",
    "\n",
    "  w_logistic, loss = train_logistic(Xtilde, y, \\\n",
    "                                  learning_rate = 0.5,\\\n",
    "                                  num_iterations = 1000,\\\n",
    "                                  return_history = True)\n",
    "\n",
    "  # Print the final weight and loss\n",
    "  print(\"Final weight:\\n\", w_logistic)\n",
    "  print(\"Final loss:\\n\", loss[-1])\n",
    "  y_pred = predict_logistic(Xtilde, w_logistic)\n",
    "  errors = count_errors(y, y_pred)\n",
    "  print(\"Number of misclassified examples: \", errors)\n",
    "    \n",
    "  plt.figure(figsize = (6,4))\n",
    "  plt.plot(loss)\n",
    "  plt.xlabel('Iteration #')\n",
    "  plt.ylabel('Cross Entropy Loss')\n",
    "  plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
